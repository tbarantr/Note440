---
layout: default
title: 5. Replication - weak consistency model protocols
parent: Distributed systems for fun and profit
nav_order: 5
---
# Chapter 5: Replication: weak consistency model protocols
* enforcing order is expensive
* Eventual consistency
  - Nodes can for some time diverge from each other, but that eventually they will agree on the value
  - Eventual consistency with probabilistic guarantees
    - detect conflicting writes at some later point, but does not guarantee that the results are equivalent to some correct sequential execution
    - Amazon's Dynamo
  - Eventual consistency with strong guarantees
    - guarantees that the results converge to a common value equivalent to some correct sequential execution
* CRDT (convergent replicated data types) are data types that guarantee convergence to the same value in spite of network delays, partitions and message reordering
* The CALM (consistency as logical monotonicity) conjecture equates logical monotonicity with convergence.
  - help to decide when and where to apply coordination techniques

## Reconciling different operation orders
* Scenario 1: each partition handles distinct set of clients
```
[Clients]   - > [A]
--- Partition ---
[Clients]   - > [B]
--- Partition ---
[Clients]   - > [C]
```
```
[A] \
    --> [merge]
[B] /     |
          |
[C] ----[merge]---> result
```

* Scenario 2: without coordination, each host receive updates in different order
```
[Clients]  --> [A]  1, 2, 3
[Clients]  --> [B]  2, 3, 1
```

## Amazon's Dynamo
* eventually consistent, highly available key-value store
* prioritizes availability over consistency
* replicas may diverge from each other when values are written
* there is a read reconciliation phase that attempts to reconcile differences between replicas before returning the value back to the client
* basis for Linkedin's Voldemort, Facebook's Cassandra and Basho's Riak
```
[ Client ]
    |
( Mapping keys to nodes )
    |
    V
[ Node A ]
    |     \
( Synchronous replication task: minimum durability )
    |        \
[ Node B]  [ Node C ]
    A
    |
( Conflict detection; asynchronous replication task:
  ensuring that partitioned / recovered nodes recover )
    |
    V
[ Node D]
```

### Consistent hashing
* key-to-node mapping can be calculated on client

### Partial quorums
* synchronous for higher level of duratibility
* sloppy (partial) quorums instead of strict (majority) quorums
* different subsets of the quorum may contain different versions of data
* the user choose:
  - W-of-N nodes required for a write
  - R-of-N nodes required for a read
  - usually `N = 3`
  - usual recommendation: `R + W > N`:
    - `R = 1, W = N`: fast reads, slow writes
    - `R = N, W = 1`: fast writes, slow reads
    - `R = N/2` and `W = N/2 + 1`: favorable to both
  - how many messages per read/write?
    - `N`: less sensitive to latency, less efficient (more messages to send)
    - `R/W`: more sensitive to latency, more efficient
* this is not "strong consistency"
  - node failures => a different unrelated node will be added; even quorum sizes are equal to N, the nodes in those quorums can change
  -during partition, writes might be allowed on both sides of a partition; for some time the system does not act as a single copy

### Conflict detection and read repair
* systems that allow diverging replicas eventually need to reconcile two different values
* generally, this is done by tracking the history of data by cupplementing it with some metadata, like vector clocks
* alternatives:
  - __no metadata__: nothing can be done for conflicting writes
  - __timestamps__: higher timstamp wins; susceptible to poorly synchronized clock, like faulty/fast clock
  - __version numbers__: can avoid some issues related to timestamps, but not enough to track causality
  - __vector clocks__:
    - can detect concurrent and out of date updates, but sometimes the client needs to picka value
    - takes all responses and discard values taht are strictly older
      - if there is only one {vector clock, value} pair, it returns that
      - otherwise, return all pairs

### Replica synchronization: gossip and Merkle trees
* a way to deal with nodes rejoining the cluster
* synchronization happens after a failure and periodically
* Gossip
  - a probabilistic technique for synchronizing replicas
  - pattern of communication not determined in advance
  - every `t` seconds, each nodes picks a node to communicate
  - scalable, no single point of failure, but only provides probabilistic guarantees
* Merkle trees
  - a hashing mechanism
  - a data store can be hashed at multiple different levels of granularity, representing the whole content, half of the key spaces, a quarter of the keys, etc.
  - nodes can use hashing to compare data store content more efficiently

### Dynamo Summary
* consistent hashing to determine key placement
* partial quorums for reading and writing
* conflict detection and read repair via vector clocks and
* gossip for replica synchronization

## probabilistically bounded staleness (PBS)
* PBS is an approach that uses Monte Carlo simulation to characterize the expected behavior of such a system
* real world informatiion needed:
  - anti-entropy (gossip) rate
  - network latency
  - local processing delay

## Convergent replicated datatypes (CRDTs)
### Disorderly Programming
* semantic of operations matters--whehter they are commutative or not
  - READ/WRITE semantic is not commutative so an order on the operations need to be imposed
* It is likely not possible to write a merge procedure that works for all data types.
  - so the best that can be done is to expose it and ask the application to handle each conflict.

### CRDTs
* CRDTs exploit knowledge regarding the commutativity and associativity of specific operations on specific datatypes.
* identities:
  - Associative `a+(b+c)=(a+b)+c`, so that grouping doesn't matter
  - Commutative `a+b=b+a`, so that order of application doesn't matter
  - Idempotent `a+a=a`, so that duplication does not matter
* Some math concepts
  - lattice is a partially ordered set with a distinct top (least upper bound) and a distinct bottom (greatest lower bound)
  - A semilattice is like a lattice, but one that only has a distinct top or bottom
    - A join semilattice is one with a distinct top (least upper bound)
    - a meet semilattice is one with a distinct bottom (greatest lower bound)
* Any data type that be expressed as a semilattice can be implemented as a data structure which guarantees convergence
* However, expressing a data type as a semilattice often requires some level of interpretation, so data types will have more specialized implementations as CRDT
* Examples,
  - Counters
    - Grow-only counter (merge = max(values); payload = single integer)
    - Positive-negative counter (consists of two grow counters, one for increments and another for decrements)
  - Registers
    - Last Write Wins -register (timestamps or version numbers; merge = max(ts); payload = blob)
    - Multi-valued -register (vector clocks; merge = take both)
  - Sets
    - Grow-only set (merge = union(items); payload = set; no removal)
    - Two-phase set (consists of two sets, one for adding, and another for removing; elements can be added once and removed once)
    - Unique set (an optimized version of the two-phase set)
    - Last write wins set (merge = max(ts); payload = set)
    - Positive-negative set (consists of one PN-counter per set item)
    - Observed-remove set
  - Graphs and text sequences (see paper from Shapiro, 2011)

## The CALM theorem
* there are many programming models in which the order of statements does not play a significant role
  - tasks are expressed in a declarative language where the order of execution is not explicitly specified
  - for example, SQL and MapReduce
  - execution order is up to the scheduler/optimizaer
  - it is possible to execute such programs without coordination

### the theorem
* It states that logically monotonic programs are guaranteed to be eventually consistent without any need for coordination protocols (distributed locks, two-phase commit, paxos, etc.)
* monotony
  - if sentence φ is a consequence of a set of premises Γ, then it can also be inferred from any set Δ of premises extending Γ
  - Monotonicity concerns the relationship between premises and conclusions
  - Informally, a block of code is logically monotonic if adding things to the input can only increase the output. By contrast, non-monotonic code may need to “retract” a previous output if more is added to its input.
  - negation and aggregation are not monotonic

### Real world
* if computation can be expressed in a manner in which it is possible to test for monotonicity
  - then we can detect which parts of the program are safe to run without coordination; and which parts are not
* A different language is required (Bloom), such inferences are hard for traditional programming languages

### What is non-mononicity good for?
